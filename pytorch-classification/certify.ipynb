{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69998e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import models.cifar as models\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb692f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_under_noise(model, x, n, sigma, batch=100):\n",
    "    noisy_images = x + sigma * torch.randn((n, *x.shape[1:]))\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))(noisy_images)\n",
    "    preds = []\n",
    "    for i in range(math.ceil(n/batch)):\n",
    "        batched = noisy_images[i * batch: (i + 1) * batch]\n",
    "        logits = model(batched)\n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "        preds.append(pred)\n",
    "    return torch.cat(preds).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1985598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched_sample_under_noise(model, x, n, sigma):\n",
    "    noisy_images = x + sigma * torch.randn(x.size())\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))(noisy_images)\n",
    "    preds = []\n",
    "    for i in range(n):\n",
    "        logits = model(noisy_images)\n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "        preds.append(pred.unsqueeze(-1))\n",
    "    return torch.cat(preds, dim=1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4869ce34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, sigma, x, n=1000, alpha=0.001):\n",
    "    preds = sample_under_noise(model, x, n, sigma).astype(int)\n",
    "    counts = np.bincount(preds)\n",
    "    cA = np.argmax(counts)\n",
    "    nA, nB = counts[np.argpartition(counts, 2)[:2]]\n",
    "    if scipy.stats.binom_test(max(nA, nB), nA + nB, 0.5) <= alpha:\n",
    "        return cA\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686ad0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched_predict(model, sigma, x, n=1000, alpha=0.001):\n",
    "    preds = batched_sample_under_noise(model, x, n, sigma).astype(int)\n",
    "    print(preds.shape)\n",
    "    results = []\n",
    "    for i in range(preds.shape[0]):\n",
    "        counts = np.bincount(preds[i])\n",
    "        cA = np.argmax(counts)\n",
    "        if len(counts) < 2:\n",
    "            results.append(cA)\n",
    "        else:\n",
    "            nA, nB = counts[np.argpartition(counts, 2)[:2]]\n",
    "            if scipy.stats.binom_test(max(nA, nB), nA + nB, 0.5) <= alpha:\n",
    "                results.append(cA)\n",
    "            else:\n",
    "                results.append(-1)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17652375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def certify(model, sigma, x, n0=100, n=100000, alpha=0.001):\n",
    "    preds0 = sample_under_noise(model, x, n0, sigma).astype(int)\n",
    "    counts0 = np.bincount(preds0)\n",
    "    cA = np.argmax(counts0)\n",
    "    preds = sample_under_noise(model, x, n, sigma).astype(int)\n",
    "    counts = np.bincount(preds)\n",
    "    pA = proportion_confint(counts[cA], n, alpha=2*alpha, method='beta')[0]\n",
    "    if pA > 0.5:\n",
    "        return cA, sigma * scipy.stats.norm.ppf(pA)\n",
    "    return -1, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63979956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched_certify(model, sigma, x, n0=100, n=100000, alpha=0.001):\n",
    "    preds0 = batched_sample_under_noise(model, x, n0, sigma).astype(int)\n",
    "    counts0 = np.bincount(preds0)\n",
    "    cA = np.argmax(counts0)\n",
    "    preds = sample_under_noise(model, x, n, sigma).astype(int)\n",
    "    results = []\n",
    "    for i in range(x.shape[0]):\n",
    "        counts = np.bincount(preds[i])\n",
    "        pA = proportion_confint(counts[cA], n, alpha=2*alpha, method='beta')[0]\n",
    "        if pA > 0.5:\n",
    "            results.append([cA, sigma * scipy.stats.norm.ppf(pA)])\n",
    "        else:\n",
    "            results.append([-1, 0])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0e4448",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.__dict__['resnet'](\n",
    "    num_classes=10,\n",
    "    depth=110,\n",
    "    block_name='BasicBlock',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb02c2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = '/pasteur/results/jeff-results/pretrained-models/models/cifar10/resnet110/noise_0.12/checkpoint.pth.tar'\n",
    "if 'pretrained-models' in saved_model:\n",
    "    pretrained = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b50666a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(saved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d11b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = checkpoint['state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661eaa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pretrained:\n",
    "    for k in list(state_dict.keys()):\n",
    "        # retain only encoder_q up to before the embedding layer\n",
    "        if k.startswith('1.'):\n",
    "            # remove prefix\n",
    "            state_dict[k[len(\"1.\"):]] = state_dict[k]\n",
    "        # delete renamed or unused k\n",
    "        del state_dict[k]\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b2e060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709e5e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49741aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = datasets.CIFAR10(root='/pasteur/data', train=False, download=False, transform=transform_test)\n",
    "testloader = data.DataLoader(testset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359f2df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test predict\n",
    "pred_acc = 0\n",
    "abstain = 0\n",
    "t0 = time.time()\n",
    "for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "    pred = predict(model, sigma=0.12, x=inputs, n=1000, alpha=0.001)\n",
    "    if pred == targets.item():\n",
    "        pred_acc += 1\n",
    "    if pred == -1:\n",
    "        abstain += 1\n",
    "    if batch_idx == 1:\n",
    "        break\n",
    "t1 = time.time()    \n",
    "print('Total time:', t1 - t0)\n",
    "print('Average time:', (t1 - t0)/(batch_idx + 1))\n",
    "print('Abstain precent:', abstain/(batch_idx + 1))\n",
    "print('Predicted accuracy:', pred_acc/(batch_idx + 1 - abstain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad29ad12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test certify\n",
    "cert_acc = 0\n",
    "abstain = 0\n",
    "results = []\n",
    "all_targets = []\n",
    "t0 = time.time()\n",
    "for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "    pred, radius = certify(model, sigma=0.12, x=inputs, n=1000, alpha=0.001)\n",
    "    results.append([pred, radius])\n",
    "    all_targets = all_targets + list(targets.cpu().numpy())\n",
    "    if batch_idx == 1:\n",
    "        break\n",
    "t1 = time.time()    \n",
    "print('Total time:', t1 - t0)\n",
    "print('Average time:', (t1 - t0)/(batch_idx + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e9da50",
   "metadata": {},
   "outputs": [],
   "source": [
    "cert_acc = 0\n",
    "abstain = 0\n",
    "for i in range(len(results)):\n",
    "    pred, radius = results[i]\n",
    "    if pred == all_targets[i]:\n",
    "        cert_acc += 1\n",
    "    if pred == -1:\n",
    "        abstain += 1\n",
    "print('Abstain precent:', abstain/len(results))\n",
    "print('Predicted accuracy:', pred_acc/(len(results) - abstain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bb61a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = datasets.CIFAR10(root='/pasteur/data', train=False, download=False, transform=transform_test)\n",
    "testloader = data.DataLoader(testset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2016273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test batched predict\n",
    "results = []\n",
    "t0 = time.time()\n",
    "all_targets = []\n",
    "for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "    result = batched_predict(model, sigma=0.12, x=inputs, n=1000, alpha=0.001)\n",
    "    results = results + result\n",
    "    all_targets = all_targets + list(targets.cpu().numpy())\n",
    "    if batch_idx == 0:\n",
    "        break\n",
    "t1 = time.time()    \n",
    "print('Total time:', t1 - t0)\n",
    "print('Average time:', (t1 - t0)/len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c9114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_acc = 0\n",
    "abstain = 0\n",
    "for i in range(len(results)):\n",
    "    pred = results[i]\n",
    "    if pred == all_targets[i]:\n",
    "        pred_acc += 1\n",
    "    if pred == -1:\n",
    "        abstain += 1\n",
    "print('Abstain precent:', abstain/len(results))\n",
    "print('Predicted accuracy:', pred_acc/(len(results) - abstain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabd2bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test batched certify\n",
    "results = []\n",
    "all_targets = []\n",
    "t0 = time.time()\n",
    "for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "    result = predict(model, sigma=0.12, x=inputs, n=1000, alpha=0.001)\n",
    "    results = results + result\n",
    "    all_targets = all_targets + list(targets.cpu().numpy())\n",
    "    if batch_idx == 0:\n",
    "        break\n",
    "t1 = time.time()    \n",
    "print('Total time:', t1 - t0)\n",
    "print('Average time:', (t1 - t0)/len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60976f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cert_acc = 0\n",
    "abstain = 0\n",
    "for i in range(len(results)):\n",
    "    pred, radius = results[i]\n",
    "    if pred == all_targets[i]:\n",
    "        cert_acc += 1\n",
    "    if pred == -1:\n",
    "        abstain += 1\n",
    "print('Abstain precent:', abstain/len(results))\n",
    "print('Predicted accuracy:', cert_acc/(len(results) - abstain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d89dcf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
