{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69998e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import models.cifar as models\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb692f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_under_noise(model, x, n, sigma, batch=100):\n",
    "    noisy_images = x + sigma * torch.randn((n, *x.shape[1:]))\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))(noisy_images)\n",
    "    preds = []\n",
    "    for i in range(math.ceil(n/batch)):\n",
    "        batched = noisy_images[i * batch: (i + 1) * batch]\n",
    "        logits = model(batched)\n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "        preds.append(pred)\n",
    "    return torch.cat(preds).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1985598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched_sample_under_noise(model, x, n, sigma):\n",
    "    noisy_images = x + sigma * torch.randn(x.size())\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))(noisy_images)\n",
    "    preds = []\n",
    "    for i in range(n):\n",
    "        logits = model(noisy_images)\n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "        preds.append(pred.unsqueeze(-1))\n",
    "    return torch.cat(preds, dim=1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4869ce34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, sigma, x, n=1000, alpha=0.001):\n",
    "    preds = sample_under_noise(model, x, n, sigma).astype(int)\n",
    "    counts = np.bincount(preds)\n",
    "    cA = np.argmax(counts)\n",
    "    nA, nB = counts[np.argpartition(counts, 2)[:2]]\n",
    "    if scipy.stats.binom_test(max(nA, nB), nA + nB, 0.5) <= alpha:\n",
    "        return cA\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "686ad0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched_predict(model, sigma, x, n=1000, alpha=0.001):\n",
    "    preds = batched_sample_under_noise(model, x, n, sigma).astype(int)\n",
    "    print(preds.shape)\n",
    "    results = []\n",
    "    for i in range(preds.shape[0]):\n",
    "        counts = np.bincount(preds[i])\n",
    "        cA = np.argmax(counts)\n",
    "        if len(counts) < 2:\n",
    "            results.append(cA)\n",
    "        else:\n",
    "            nA, nB = counts[np.argpartition(counts, 2)[:2]]\n",
    "            if scipy.stats.binom_test(max(nA, nB), nA + nB, 0.5) <= alpha:\n",
    "                results.append(cA)\n",
    "            else:\n",
    "                results.append(-1)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17652375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def certify(model, sigma, x, n0=100, n=100000, alpha=0.001):\n",
    "    preds0 = sample_under_noise(model, x, n0, sigma).astype(int)\n",
    "    counts0 = np.bincount(preds0)\n",
    "    cA = np.argmax(counts0)\n",
    "    preds = sample_under_noise(model, x, n, sigma).astype(int)\n",
    "    counts = np.bincount(preds)\n",
    "    pA = proportion_confint(counts[cA], n, alpha=2*alpha, method='beta')[0]\n",
    "    if pA > 0.5:\n",
    "        return cA, sigma * scipy.stats.norm.ppf(pA)\n",
    "    return -1, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63979956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched_certify(model, sigma, x, n0=100, n=100000, alpha=0.001):\n",
    "    preds0 = batched_sample_under_noise(model, x, n0, sigma).astype(int)\n",
    "    counts0 = np.bincount(preds0)\n",
    "    cA = np.argmax(counts0)\n",
    "    preds = sample_under_noise(model, x, n, sigma).astype(int)\n",
    "    results = []\n",
    "    for i in range(x.shape[0]):\n",
    "        counts = np.bincount(preds[i])\n",
    "        pA = proportion_confint(counts[cA], n, alpha=2*alpha, method='beta')[0]\n",
    "        if pA > 0.5:\n",
    "            results.append([cA, sigma * scipy.stats.norm.ppf(pA)])\n",
    "        else:\n",
    "            results.append([-1, 0])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e0e4448",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.__dict__['resnet'](\n",
    "    num_classes=10,\n",
    "    depth=110,\n",
    "    block_name='BasicBlock',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb02c2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = '/pasteur/results/jeff-results/pretrained-models/models/cifar10/resnet110/noise_0.12/checkpoint.pth.tar'\n",
    "if 'pretrained-models' in saved_model:\n",
    "    pretrained = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b50666a",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(saved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9d11b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = checkpoint['state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "661eaa97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if pretrained:\n",
    "    for k in list(state_dict.keys()):\n",
    "        # retain only encoder_q up to before the embedding layer\n",
    "        if k.startswith('1.'):\n",
    "            # remove prefix\n",
    "            state_dict[k[len(\"1.\"):]] = state_dict[k]\n",
    "        # delete renamed or unused k\n",
    "        del state_dict[k]\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15b2e060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "709e5e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49741aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = datasets.CIFAR10(root='/pasteur/data', train=False, download=False, transform=transform_test)\n",
    "testloader = data.DataLoader(testset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "359f2df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 15.585898399353027\n",
      "Average time: 7.792949199676514\n",
      "Abstain precent: 0.0\n",
      "Predicted accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# test predict\n",
    "pred_acc = 0\n",
    "abstain = 0\n",
    "t0 = time.time()\n",
    "for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "    pred = predict(model, sigma=0.12, x=inputs, n=1000, alpha=0.001)\n",
    "    if pred == targets.item():\n",
    "        pred_acc += 1\n",
    "    if pred == -1:\n",
    "        abstain += 1\n",
    "    if batch_idx == 1:\n",
    "        break\n",
    "t1 = time.time()    \n",
    "print('Total time:', t1 - t0)\n",
    "print('Average time:', (t1 - t0)/(batch_idx + 1))\n",
    "print('Abstain precent:', abstain/(batch_idx + 1))\n",
    "print('Predicted accuracy:', pred_acc/(batch_idx + 1 - abstain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad29ad12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 16.708078861236572\n",
      "Average time: 8.354039430618286\n"
     ]
    }
   ],
   "source": [
    "# test certify\n",
    "cert_acc = 0\n",
    "abstain = 0\n",
    "results = []\n",
    "all_targets = []\n",
    "t0 = time.time()\n",
    "for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "    pred, radius = certify(model, sigma=0.12, x=inputs, n=1000, alpha=0.001)\n",
    "    results.append([pred, radius])\n",
    "    all_targets = all_targets + list(targets.cpu().numpy())\n",
    "    if batch_idx == 1:\n",
    "        break\n",
    "t1 = time.time()    \n",
    "print('Total time:', t1 - t0)\n",
    "print('Average time:', (t1 - t0)/(batch_idx + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08e9da50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstain precent: 1.0\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-0d98a3098c23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mabstain\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Abstain precent:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabstain\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicted accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_acc\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mabstain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "cert_acc = 0\n",
    "abstain = 0\n",
    "for i in range(len(results)):\n",
    "    pred, radius = results[i]\n",
    "    if pred == all_targets[i]:\n",
    "        cert_acc += 1\n",
    "    if pred == -1:\n",
    "        abstain += 1\n",
    "print('Abstain precent:', abstain/len(results))\n",
    "print('Predicted accuracy:', pred_acc/(len(results) - abstain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebcec23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = datasets.CIFAR10(root='/pasteur/data', train=False, download=False, transform=transform_test)\n",
    "testloader = data.DataLoader(testset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2016273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 1000)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "kth(=2) out of bounds (2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-5d7cc57d19fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mall_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatched_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mall_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_targets\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-54bbcc7da3cf>\u001b[0m in \u001b[0;36mbatched_predict\u001b[0;34m(model, sigma, x, n, alpha)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mnA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinom_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnA\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margpartition\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/pasteur/u/jeffgu/miniconda3/envs/cs329/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margpartition\u001b[0;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m     \"\"\"\n\u001b[0;32m--> 837\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argpartition'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/pasteur/u/jeffgu/miniconda3/envs/cs329/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: kth(=2) out of bounds (2)"
     ]
    }
   ],
   "source": [
    "# test batched predict\n",
    "results = []\n",
    "t0 = time.time()\n",
    "all_targets = []\n",
    "for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "    result = batched_predict(model, sigma=0.12, x=inputs, n=1000, alpha=0.001)\n",
    "    results = results + result\n",
    "    all_targets = all_targets + list(targets.cpu().numpy())\n",
    "    if batch_idx == 0:\n",
    "        break\n",
    "t1 = time.time()    \n",
    "print('Total time:', t1 - t0)\n",
    "print('Average time:', (t1 - t0)/len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c819c0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_acc = 0\n",
    "abstain = 0\n",
    "for i in range(len(results)):\n",
    "    pred = results[i]\n",
    "    if pred == all_targets[i]:\n",
    "        pred_acc += 1\n",
    "    if pred == -1:\n",
    "        abstain += 1\n",
    "print('Abstain precent:', abstain/len(results))\n",
    "print('Predicted accuracy:', pred_acc/(len(results) - abstain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabd2bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test batched certify\n",
    "results = []\n",
    "all_targets = []\n",
    "t0 = time.time()\n",
    "for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "    result = predict(model, sigma=0.12, x=inputs, n=1000, alpha=0.001)\n",
    "    results = results + result\n",
    "    all_targets = all_targets + list(targets.cpu().numpy())\n",
    "    if batch_idx == 0:\n",
    "        break\n",
    "t1 = time.time()    \n",
    "print('Total time:', t1 - t0)\n",
    "print('Average time:', (t1 - t0)/len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8766d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "cert_acc = 0\n",
    "abstain = 0\n",
    "for i in range(len(results)):\n",
    "    pred, radius = results[i]\n",
    "    if pred == all_targets[i]:\n",
    "        cert_acc += 1\n",
    "    if pred == -1:\n",
    "        abstain += 1\n",
    "print('Abstain precent:', abstain/len(results))\n",
    "print('Predicted accuracy:', cert_acc/(len(results) - abstain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c005b4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
